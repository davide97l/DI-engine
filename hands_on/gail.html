

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>GAIL &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TREX" href="trex.html" />
    <link rel="prev" title="HER" href="her.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">RL Algorithm Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_tutorial/index.html">RL Environments Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed/index.html">Distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature/index.html">Feature</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../specification/index.html">Middleware code specification</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">RL Algorithm Cheat Sheet</a> &raquo;</li>
        
      <li>GAIL</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/hands_on/gail.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="gail">
<h1>GAIL<a class="headerlink" href="#gail" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>GAIL (Generative Adversarial Imitation Learning) was first proposed in
<a class="reference external" href="https://arxiv.org/abs/1606.03476">Generative Adversarial Imitation
Learning</a>, is a general framework
for directly extracting policy from data, as if it were obtained by
reinforcement learning following inverse reinforcement learning.
The authors deduced the optimization objective of GAIL from the
perspective of occupancy measure.
Compared to other learning methods, GAIL neither suffers from
the compounding error problem in imitation learning, nor needs to
expensively learn the inter-mediate reward function as in inverse
reinforcement learning. But similar to other methods, GAIL is also
exposed to “the curse of dimensionality”, which makes the scalability
much valuable in high-dimension-space problems.</p>
</div>
<div class="section" id="quick-facts">
<h2>Quick Facts<a class="headerlink" href="#quick-facts" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>GAIL consists of a generator and a discriminator, trained in an
adversarial manner.</p></li>
<li><p>The generator is optimized for a surrogate reward provided by the
discriminator, usually by policy-gradient reinforcement learning
methods, like TRPO, for its sampling nature.</p></li>
<li><p>The discriminator can be simply optimized by typical gradient descent
methods, like Adam, to distinguish expert and generated data.</p></li>
</ol>
</div>
<div class="section" id="key-equations-or-key-graphs">
<h2>Key Equations or Key Graphs<a class="headerlink" href="#key-equations-or-key-graphs" title="Permalink to this headline">¶</a></h2>
<p>The objective function in GAIL’s adversarial training is as below:</p>
<div class="figure align-center">
<img alt="../_images/gail_loss.png" src="../_images/gail_loss.png" />
</div>
<p>where pi is the generator policy, D is the discriminator policy,
while <span class="math notranslate nohighlight">\(H(\pi)\)</span> is the causal entropy of policy pi. This is a
min-max optimization process, and the objective is optimized in an
iterative adversarial manner. During training, D has to
maximize the objective, while pi has to counter D by minimizing the
objective.</p>
</div>
<div class="section" id="pseudo-code">
<h2>Pseudo-Code<a class="headerlink" href="#pseudo-code" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default">
<img alt="" src="../_images/GAIL.png" />
</div>
</div>
<div class="section" id="extensions">
<h2>Extensions<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>MAGAIL (Multi-Agent Generative Adversarial Imitation Learning)</p>
<p>Multi-agent systems tend to be much more complicated, due to the
heterogeneity, stochasticity, and interaction among multi-agents.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1807.09936">MAGAIL：Multi-Agent Generative Adversarial Imitation
Learning</a> extended GAIL to
multi-agent scenarios. The generator is redefined as a policy
controlling all agents in a distributed manner, while the
discriminator is distinguishing expert and generates behavior for
each agent.</p>
<p>The Pseudo-Code is as following:</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/MAGAIL.png"><img alt="" src="../_images/MAGAIL.png" style="width: 1036.1499999999999px; height: 852.55px;" /></a>
</div>
</li>
<li><p>Other perspectives to understand GAIL</p>
<p>GAIL is closely related to other learning methods, and thus can be
understood in different views.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1611.03852">A Connection Between Generative Adversarial Networks, Inverse
Reinforcement Learning, and Energy-Based
Models</a> indicated GAIL’s
implicit connection to GAN, IRL, and energy-based probability
estimation.</p>
</li>
</ul>
</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<p>The default config is defined as follows:</p>
<dl class="py class">
<dt class="sig sig-object py" id="ding.reward_model.gail_irl_model.GailRewardModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">ding.reward_model.gail_irl_model.</span></span><span class="sig-name descname"><span class="pre">GailRewardModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">easydict.EasyDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_logger</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">SummaryWriter</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/reward_model/gail_irl_model.html#GailRewardModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ding.reward_model.gail_irl_model.GailRewardModel" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>The Gail reward model class (<a class="reference external" href="https://arxiv.org/abs/1606.03476">https://arxiv.org/abs/1606.03476</a>)</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">estimate</span></code>, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">load_expert_data</span></code>, <code class="docutils literal notranslate"><span class="pre">collect_data</span></code>, <code class="docutils literal notranslate"><span class="pre">clear_date</span></code>,             <code class="docutils literal notranslate"><span class="pre">__init__</span></code>,  <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">learn</span></code></p>
</dd>
<dt>Config:</dt><dd><dl>
<dt>1  <code class="docutils literal notranslate"><span class="pre">type</span></code>              str        gail            | RL policy register name, refer  | this arg is optional,</dt><dd><div class="line-block">
<div class="line">to registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code> | a placeholder</div>
</div>
</dd>
<dt>2  | <a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id7"><span class="problematic" id="id8">expert_data_</span></a>      str        expert_data.    | Path to the expert dataset      | Should be a ‘.pkl’</dt><dd><div class="line-block">
<div class="line">path``                       .pkl            |                                 | file</div>
</div>
</dd>
<dt>3  | <a href="#id3"><span class="problematic" id="id4">``</span></a><a href="#id9"><span class="problematic" id="id10">update_per_</span></a>       int        100             | Number of updates per collect   |</dt><dd><div class="line-block">
<div class="line">collect``                                   |                                 |</div>
</div>
</dd>
</dl>
<p>4  | <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>      int        64              | Training batch size             |
5  | <code class="docutils literal notranslate"><span class="pre">input_size</span></code>      int                        | Size of the input:              |</p>
<blockquote>
<div><div class="line-block">
<div class="line">| obs_dim + act_dim               |</div>
</div>
</div></blockquote>
<dl>
<dt>6  | <a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id11"><span class="problematic" id="id12">target_new_</span></a>       int        64              | Collect steps per iteration     |</dt><dd><div class="line-block">
<div class="line">data_count``                                |                                 |</div>
</div>
</dd>
</dl>
<p>7  | <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>     int        128             | Linear model hidden size        |
8  | <code class="docutils literal notranslate"><span class="pre">collect_count</span></code>   int        100000          | Expert dataset size             | One entry is a (s,a)</p>
<blockquote>
<div><div class="line-block">
<div class="line">|                                 | tuple</div>
</div>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 12%" />
<col style="width: 38%" />
<col style="width: 19%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>environment</p></th>
<th class="head"><p>best mean reward</p></th>
<th class="head"><p>evaluation results</p></th>
<th class="head"><p>config link</p></th>
<th class="head"><p>expert</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>LunarLander</p>
<p>(LunarLander-v2)</p>
</td>
<td><p>200</p></td>
<td><img alt="../_images/lunarlander_gail.png" src="../_images/lunarlander_gail.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/box2d/lunarlander/config/lunarlander_dqn_gail_config.py">config_link_l</a></p></td>
<td><p>DQN</p></td>
</tr>
<tr class="row-odd"><td><p>BipedalWalker</p>
<p>(BipedalWalker-v3)</p>
</td>
<td><p>300</p></td>
<td><img alt="../_images/bipedalwalker_gail.png" src="../_images/bipedalwalker_gail.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/box2d/bipedalwalker/config/bipedalwalker_sac_gail_config.py">config_link_b</a></p></td>
<td><p>SAC</p></td>
</tr>
<tr class="row-even"><td><p>Hopper</p>
<p>(Hopper-v3)</p>
</td>
<td><p>3500</p></td>
<td><img alt="../_images/hopper_gail.png" src="../_images/hopper_gail.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/tree/main/dizoo/mujoco/config/hopper_sac_gail_default_config.py">config_link_h</a></p></td>
<td><p>SAC</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Ho, Jonathan, and Stefano Ermon. Making efficient use of demonstrations to solve hard exploration problems. [<a class="reference external" href="https://arxiv.org/abs/1606.03476">https://arxiv.org/abs/1606.03476</a> arXiv:1606.03476], 2019.</p></li>
<li><p>Song, Jiaming, et al. Multi-agent generative adversarial imitation learning. [<a class="reference external" href="https://arxiv.org/abs/1807.09936">https://arxiv.org/abs/1807.09936</a> arXiv:1807.09936], 2018.</p></li>
<li><p>Finn, Chelsea, et al. A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models. [<a class="reference external" href="https://arxiv.org/abs/1611.03852">https://arxiv.org/abs/1611.03852</a> arXiv:1611.03852], 2016.</p></li>
</ul>
</div>
<div class="section" id="other-public-implementations">
<h2>Other Public Implementations<a class="headerlink" href="#other-public-implementations" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://stable-baselines.readthedocs.io/en/master/modules/gail.html">Baselines</a></p></li>
<li><p><a class="reference external" href="https://github.com/Khrylx/PyTorch-RL">PyTorch-RL</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="trex.html" class="btn btn-neutral float-right" title="TREX" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="her.html" class="btn btn-neutral float-left" title="HER" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>